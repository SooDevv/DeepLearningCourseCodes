{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq2Seq.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"-rCV3S81bAjl","colab_type":"text"},"cell_type":"markdown","source":["Neural Machine Translation \n","- Many-to-Many\n","Data set\n","- original : http://www.statmt.org/wmt14/translation-task.html"]},{"metadata":{"id":"wNbefMjxcYov","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":339},"outputId":"21e869ad-1e10-4353-8310-5f6fe8a8246e","executionInfo":{"status":"ok","timestamp":1534468475685,"user_tz":-540,"elapsed":49504,"user":{"displayName":"Soojung Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102985936235903055217"}}},"cell_type":"code","source":["!pip3 install torch torchvision"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting torch\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n","\u001b[K    100% |████████████████████████████████| 519.5MB 31kB/s \n","tcmalloc: large alloc 1073750016 bytes == 0x58676000 @  0x7f94393e31c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n","\u001b[?25hCollecting torchvision\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 2.2MB/s \n","\u001b[?25hCollecting pillow>=4.1.1 (from torchvision)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/24/f53ff6b61b3d728b90934bddb4f03f8ab584a7f49299bf3bde56e2952612/Pillow-5.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n","\u001b[K    100% |████████████████████████████████| 2.0MB 2.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n","Installing collected packages: torch, pillow, torchvision\n","  Found existing installation: Pillow 4.0.0\n","    Uninstalling Pillow-4.0.0:\n","      Successfully uninstalled Pillow-4.0.0\n","Successfully installed pillow-5.2.0 torch-0.4.1 torchvision-0.2.1\n"],"name":"stdout"}]},{"metadata":{"id":"xe__r1K_dG50","colab_type":"text"},"cell_type":"markdown","source":["# **데이터 다운로드**"]},{"metadata":{"id":"luVXwWs1a72e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":604},"outputId":"ee3f9784-f5ef-4db5-ce65-c99baff60675","executionInfo":{"status":"ok","timestamp":1534468624067,"user_tz":-540,"elapsed":60355,"user":{"displayName":"Soojung Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102985936235903055217"}}},"cell_type":"code","source":["# 10만개의 영어 문장 데이터 다운로드\n","!wget https://goo.gl/DBcpZg -O en.txt\n","# 10만개 프랑스 문장 데이터 다운로드\n","!wget https://goo.gl/AuBFga -O fr.txt\n","!ls"],"execution_count":3,"outputs":[{"output_type":"stream","text":["--2018-08-17 01:16:07--  https://goo.gl/DBcpZg\n","Resolving goo.gl (goo.gl)... 74.125.201.102, 74.125.201.100, 74.125.201.139, ...\n","Connecting to goo.gl (goo.gl)|74.125.201.102|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: http://davian.korea.ac.kr/filemanager/wl/?id=tEOi7IVh1ICcSe38jjNPTGAcAotwEzp2 [following]\n","--2018-08-17 01:16:07--  http://davian.korea.ac.kr/filemanager/wl/?id=tEOi7IVh1ICcSe38jjNPTGAcAotwEzp2\n","Resolving davian.korea.ac.kr (davian.korea.ac.kr)... 163.152.29.74\n","Connecting to davian.korea.ac.kr (davian.korea.ac.kr)|163.152.29.74|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 7186902 (6.9M) [application/octet-stream]\n","Saving to: ‘en.txt’\n","\n","en.txt              100%[===================>]   6.85M   329KB/s    in 23s     \n","\n","2018-08-17 01:16:34 (308 KB/s) - ‘en.txt’ saved [7186902/7186902]\n","\n","--2018-08-17 01:16:35--  https://goo.gl/AuBFga\n","Resolving goo.gl (goo.gl)... 108.177.112.100, 108.177.112.102, 108.177.112.138, ...\n","Connecting to goo.gl (goo.gl)|108.177.112.100|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: http://davian.korea.ac.kr/filemanager/wl/?id=9mneuPm7GJLzETb8aO4Op4CdvNuR4N3b [following]\n","--2018-08-17 01:16:35--  http://davian.korea.ac.kr/filemanager/wl/?id=9mneuPm7GJLzETb8aO4Op4CdvNuR4N3b\n","Resolving davian.korea.ac.kr (davian.korea.ac.kr)... 163.152.29.74\n","Connecting to davian.korea.ac.kr (davian.korea.ac.kr)|163.152.29.74|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 8116714 (7.7M) [application/octet-stream]\n","Saving to: ‘fr.txt’\n","\n","fr.txt              100%[===================>]   7.74M   335KB/s    in 26s     \n","\n","2018-08-17 01:17:05 (309 KB/s) - ‘fr.txt’ saved [8116714/8116714]\n","\n","datalab  en.txt  fr.txt  sample_data\n"],"name":"stdout"}]},{"metadata":{"id":"r1asl7KjdWsB","colab_type":"text"},"cell_type":"markdown","source":["# Split train / test set \n","- validation set : lr , hidden layer 개수 등 validation set 을 이용하여 정함 "]},{"metadata":{"id":"48qbn502c001","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"41ea1dd9-1972-43a1-a43b-30a2276ba968","executionInfo":{"status":"ok","timestamp":1534468987680,"user_tz":-540,"elapsed":905,"user":{"displayName":"Soojung Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102985936235903055217"}}},"cell_type":"code","source":["src_lines = open(\"en.txt\", \"rt\", encoding=\"utf8\").readlines()[:50000]\n","trg_lines = open(\"fr.txt\", \"rt\", encoding=\"utf8\").readlines()[:50000]\n","\n","from sklearn.model_selection import train_test_split\n","\n","src_train, src_test, trg_train, trg_test = train_test_split(src_lines, trg_lines, test_size=3000, random_state=42)\n","print(\"train size: {:,} test size: {:,}\".format(len(src_train), len(src_test)))\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["train size: 47,000 test size: 3,000\n"],"name":"stdout"}]},{"metadata":{"id":"8ubiKueOh1_Q","colab_type":"text"},"cell_type":"markdown","source":["# 단어장 만들기"]},{"metadata":{"id":"mXTtvlyDekUO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":106},"outputId":"1a57ceb9-2cb4-4d85-f9c4-faff7b6b1998","executionInfo":{"status":"ok","timestamp":1534469542231,"user_tz":-540,"elapsed":1456,"user":{"displayName":"Soojung Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102985936235903055217"}}},"cell_type":"code","source":["from collections import Counter\n","# 영어\n","src_w2i = {\n","    '<PAD>':0,\n","    '<UNK>':1,\n","    '<SOS>':2,\n","    '<EOS>':3\n","}\n","# 프랑스어\n","trg_w2i = {\n","    '<PAD>':0,\n","    '<UNK>':1,\n","    '<SOS>':2,\n","    '<EOS>':3\n","}\n","# 단어 개수\n","src_counter = Counter()\n","trg_counter = Counter()\n","for src, trg in zip(src_train, trg_train):\n","  src_counter.update(src.split(\" \"))\n","  trg_counter.update(trg.split(\" \"))\n","\n","# word to index\n","max_len = 10000 # 최대 활용할 단어 갯수\n","for index, (word, cnt) in enumerate(src_counter.most_common(max_len)):\n","  src_w2i.update({word: index + 4})\n","\n","for index, (word, cnt) in enumerate(trg_counter.most_common(max_len)):\n","  trg_w2i.update({word: index + 4})  \n","\n","# index to word \n","src_i2w = dict(zip(src_w2i.values(), src_w2i.keys()))\n","trg_i2w = dict(zip(trg_w2i.values(), trg_w2i.keys()))\n","\n","print(list(src_w2i.items())[:10])\n","print(list(src_i2w.items())[:10])\n","print()\n","print(list(trg_w2i.items())[:10])\n","print(list(trg_i2w.items())[:10])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[('<PAD>', 0), ('<UNK>', 1), ('<SOS>', 2), ('<EOS>', 3), ('the', 4), ('to', 5), ('of', 6), ('is', 7), ('in', 8), ('a', 9)]\n","[(0, '<PAD>'), (1, '<UNK>'), (2, '<SOS>'), (3, '<EOS>'), (4, 'the'), (5, 'to'), (6, 'of'), (7, 'is'), (8, 'in'), (9, 'a')]\n","\n","[('<PAD>', 0), ('<UNK>', 1), ('<SOS>', 2), ('<EOS>', 3), ('de', 4), ('la', 5), ('le', 6), ('à', 7), ('les', 8), ('des', 9)]\n","[(0, '<PAD>'), (1, '<UNK>'), (2, '<SOS>'), (3, '<EOS>'), (4, 'de'), (5, 'la'), (6, 'le'), (7, 'à'), (8, 'les'), (9, 'des')]\n"],"name":"stdout"}]},{"metadata":{"id":"71sNnjX_h87w","colab_type":"text"},"cell_type":"markdown","source":["# Dataloader"]},{"metadata":{"id":"2NjVNe-rgVib","colab_type":"code","colab":{}},"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader \n","# 숫자가 주어지면 단어가 나오는 클래스\n","class SequenceData(Dataset):\n","  def __init__(self, src_lines, trg_lines):\n","    super(SequenceData, self).__init__()\n","    self.dataset = list(zip(src_lines, trg_lines))\n","    \n","  def __len__(self):\n","    return len(self.dataset)\n","  \n"," \n","  def __getitem__(self, item):\n","    src_sent, trg_sent = self.dataset[item]\n","    src_vec, trg_vec =[], []\n","    \n","    for word in src_sent.strip().split(\" \"):\n","      vector = src_w2i[word] if src_w2i.get(word, False) else src_w2i['<UNK>']\n","      src_vec.append(vector)\n","      \n","    for word in trg_sent.strip().split(\" \"):\n","      vector = trg_w2i[word] if trg_w2i.get(word, False) else trg_w2i['<UNK>']\n","      trg_vec.append(vector)\n","    trg_vec.append(trg_w2i['<EOS>'])\n","    \n","    \n","    return src_vec, trg_vec\n","  \n","def collate_fn(data):\n","  \"\"\"\n","  [['영어1', '영어2','영어3'], ['프랑스어1', '프랑스2', '프랑스3']]\n","  [['영어1', '프랑스1'], [영어2, 프랑스어2], [영어3, 프랑스어3]]\n","  \"\"\"\n","  batch_src, batch_trg = zip(*data)\n","  \n","  src_max_len = max([len(s) for s in batch_src])\n","  trg_max_len = max([len(s) for s in batch_trg])\n","  \n","  for s, t in zip(batch_src, batch_trg):\n","    s += [src_w2i['<PAD>']] * (src_max_len - len(s)) # 문장에 padding 을 붙여줌. 문장의 길이가 달라서 따로 처리해야되는데 padding 이 있으면 알아서 처리\n","    t += [trg_w2i['<PAD>']] * (trg_max_len - len(s))\n","    \n","  return batch_src, batch_trg"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nJU-LCzTkjyh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":392},"outputId":"537737ca-9027-4813-fdfb-1be1291d9245","executionInfo":{"status":"ok","timestamp":1534470981684,"user_tz":-540,"elapsed":841,"user":{"displayName":"Soojung Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102985936235903055217"}}},"cell_type":"code","source":["dataset = SequenceData(src_train, trg_train)\n","dataloader = DataLoader(dataset, 4, shuffle=False, num_workers=0, collate_fn=collate_fn)\n","\n","for i, (src, trg) in enumerate(dataloader): # enumerate : return 값이 쪼개짐\n","  if i == 1:\n","    break\n","    \n","    \n","  for s, t in zip(src, trg):\n","    print(len(s))\n","    print([src_i2w[v] for v in s])\n","    print(len(t))\n","    print([trg_i2w[v] for v in t])\n","    print()"],"execution_count":23,"outputs":[{"output_type":"stream","text":["19\n","['Commissioner', 'Barnier,', 'you', 'laid', 'great', 'stress', 'in', 'your', 'statement', 'on', 'the', 'importance', 'of', 'dialogue', 'with', 'the', 'citizens', 'of', '<UNK>']\n","21\n","['Monsieur', 'le', 'Commissaire', 'Barnier,', 'vous', 'avez', 'fortement', '<UNK>', 'dans', 'votre', 'déclaration,', 'sur', \"l'importance\", 'du', 'dialogue', 'avec', 'les', 'citoyens', '<UNK>', '<EOS>', '<PAD>']\n","\n","19\n","['He', 'wants', 'to', 'be', 'the', '<UNK>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n","7\n","['Il', 'veut', 'être', 'lui-même', '<UNK>', '<EOS>', '<PAD>']\n","\n","19\n","['Commissioner', \"Kinnock'\", 's', 'package', 'of', 'reforms', 'must', 'be', 'pushed', 'through', 'without', '<UNK>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n","15\n","['<UNK>', 'de', 'réformes', 'proposé', 'par', 'le', 'commissaire', 'Kinnock,', 'doit', 'être', 'adoptée', 'sans', '<UNK>', '<EOS>', '<PAD>']\n","\n","19\n","['On', 'the', 'contrary,', 'Ireland', 'is', 'doing', 'well,', 'as', 'has', 'already', 'been', 'mentioned', 'by', 'many', '<UNK>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n","20\n","['Les', 'choses', 'vont', 'tout', 'simplement', 'très', 'bien', 'en', 'Irlande', 'et', 'beaucoup', 'de', 'mes', 'collègues', \"l'\", 'ont', 'déjà', '<UNK>', '<EOS>', '<PAD>']\n","\n"],"name":"stdout"}]},{"metadata":{"id":"gwkuL84LqrrJ","colab_type":"text"},"cell_type":"markdown","source":["# Encoder model\n","- https://pytorch.org/docs/stable/nn.html#gru\n","- RNN(input, hidden, size)"]},{"metadata":{"id":"ijSRZsoZlVJZ","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yRAurC73rQsK","colab_type":"code","colab":{}},"cell_type":"code","source":["class Encoder(nn.Module):\n","  def __init__(self, vocab_size, embed_size, hidden_size, num_layers, bidirectional=False):\n","    super(Encoder, self).__init__()\n","    self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=src_w2i['<PAD>']) # word를 embedding\n","    self.rnn = rnn.GRU(embed_size, hidden_size, num_layers, batch_first=True)\n","    \n","  def forward(self, source, h):\n","    \"\"\"\n","    source : source language sentences\n","    h : initial hidden state\n","    \"\"\"\n","    \n","    #embed_input_size \n","    embed_input = self.embedding(source)\n","    \n","    \n","    encode_output, last_hidden_state = self.rnn(embed_input, h) #embedding 된 단어 vector를 rnn에 넣어줌. \n","    return encode_output, last_hidden_state"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tK_h-tkWsrxm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":212},"outputId":"2940c032-a6cd-4551-f991-0b0085624b54","executionInfo":{"status":"ok","timestamp":1534472847585,"user_tz":-540,"elapsed":726,"user":{"displayName":"Soojung Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102985936235903055217"}}},"cell_type":"code","source":["print(src)\n","src = torch.tensor(src, dtype=torch.long)\n","print(src.shape)\n","\n","encoder = Encoder(10004, 100, 200, 1, False)\n","h_0 = torch.zeros(1, src.shape[0], 200)\n","output, h_t = encoder(src, h_0)\n","\n","print(output.shape)\n","print(h_t.shape)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["tensor([[   1,    6, 1875,    1,    1,    8, 7485,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0],\n","        [  11,   37,   49,    5, 2838,   12,   18,   17,   53, 2175,    5, 1326,\n","         2114,   10, 9462,    4,    1],\n","        [ 398,   52, 2744,    5,    4, 1991,    6,    4, 9463,   54,    1,    0,\n","            0,    0,    0,    0,    0],\n","        [  15,   80,    7,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0]])\n","torch.Size([4, 17])\n","torch.Size([4, 17, 200])\n","torch.Size([1, 4, 200])\n"],"name":"stdout"}]},{"metadata":{"id":"o3EDHotrtIcU","colab_type":"code","colab":{}},"cell_type":"code","source":["class Decoder(nn.Module):\n","   def __init__(self, vocab_size, embed_size, hidden_size, num_layers, bidirectional=False):\n","    super(Decoder, self).__init__()\n","    self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=trg_w2i['<PAD>']) # word를 embedding\n","    self.rnn = rnn.GRU(embed_size, hidden_size, num_layers, batch_first=True)\n","   \n","    def forward(self, target, h):\n","      \n","      \"\"\"\n","      target : target language sentences\n","      h : initial hidden state\n","      \"\"\"\n","\n","      #embed_input_size \n","      embed_input = self.embedding(target)   \n","      decode_output, h_t = self.rnn(embed_input, h) #embedding 된 단어 vector를 rnn에 넣어줌. \n","      return decode_output, h_t\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"-gzm-lq-t4wS","colab_type":"code","colab":{}},"cell_type":"code","source":["class Seq2Seq(nn.Module):\n","  def __init__(self, vocab_size, embed_size, hidden_size, num_layers, bidirectional=False):\n","    super(Seq2Seq, self).__init__()\n","    self.hidden_size = hidden_size\n","    \n","    self.encoder = Encoder(vocab_size, embed_size, hidden_size, num_layers)\n","    self.decoder = Decoder(vocab_size, embed_size, hidden_size, num_layers)\n","    self.output_layer = nn.Sequential(nn.Linear(hidden_size, vocab_size), nn.ReLU())\n","\n","\n","   \n","  def forward(self, inputs, h_0):\n","      source, target = inputs\n","      \n","      encoder_output, h_t = self.encoder(source, h_0)\n","      decoder_output, h_t = self.decoder(target, h_t)\n","      decoder_output = decoder_output[:, :-1, :]  # [batch_size x seq_len, hidden] : for 문을 돌아야함 \n","      \n","      flatten_output = decoder_output.reshape(-1, self.hidden_size # [batch_size * seq_len, hidden] : 2차원 , rnn 돌릴때 for 문을 안돌고 matrix 상에서 계산할 수 있음.\n","      output = self.output_layer(flatten_output)\n","      \n","      return output"],"execution_count":0,"outputs":[]},{"metadata":{"id":"d3fckVaPvWU5","colab_type":"code","colab":{}},"cell_type":"code","source":["dataset = SequenceData(src_train, trg_train)\n","dataloader = DataLoader(dataset, 128, shuffle=False, num_workers=0, collate_fn=collate_fn)\n","\n","vocab_size = 10004\n","embedding_size = 300\n","hidden_size = 300\n","num_layers =2\n","model = Seq2Seq(vocab_size, enbedding_size, hidden_size, num_layers, False).cuda()\n","\n","learning_rate = 0.001\n","criterion = nn.CrossEntropyLoss(ignore_index=src_w2i['<PAD>'], reduction='sum')\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","for epoch in range(100):\n","  for step, (src, trg) in enumerate(dataloader):\n","    model.zero_grad()\n","    \n","    trg_input = [[trg_w2i['<SOS>']] + t for t in trg]\n","    scr = torch.tensor(src, dtype=torch.long).cuda()\n","    trg_input = torch.tensor(trg_input, dtype=torch.long).cuda()\n","    h_0 = torch.zeros(num_layers, len(src), hidden_size).cuda()\n","    \n","    output = mode((src, trg_input), h_0)\n","    \n","    trg = torch.tensor(trg, dtype=torch.long).cuda().reshape(-1)\n","    \n","    loss = criterion(output, trg) / src.shape[0]\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if step % 50 ==0:\n","      print(\"Epoch: {:3,} Step: {:10,} Loss: {:.3f}\".formate(epoch, step, loss))\n","      \n","  # epoch가 10일 때의 learning_rate = 0.001 * (0.9)**(11) =  0.001 * 0.3xx = 0.0003xx \n","  # epoch 돌수록 learning rate 이 줄어듬\n","  for param_group in optimizer.param_groups:\n","    param_group['lr'] = learning_rate * (0.9)**(epoch+1)"],"execution_count":0,"outputs":[]}]}