{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix 형태의 data 구조\n",
    "\n",
    "x_data = [[73, 80, 75],[93, 88, 93],[89, 91,90],[96, 98, 100],[73, 66, 70]]\n",
    "y_data = [[152], [185], [180],[196],[142]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placehoder for a tensor \n",
    "# shape : input 의 갯수를 모르므로 none 으로 설정하여 다양한 input 받을 수 있게 함\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hypothesis\n",
    "h = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(h - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize global variables and launch \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  94192.7 \n",
      " Prediction: \n",
      " [[-116.68539 ]\n",
      " [-145.46011 ]\n",
      " [-140.55939 ]\n",
      " [-154.30623 ]\n",
      " [-111.169876]]\n",
      "50 Cost:  7.8051786 \n",
      " Prediction: \n",
      " [[155.56886]\n",
      " [181.87155]\n",
      " [181.91286]\n",
      " [196.86415]\n",
      " [138.52205]]\n",
      "100 Cost:  7.600848 \n",
      " Prediction: \n",
      " [[155.51535]\n",
      " [181.90822]\n",
      " [181.89642]\n",
      " [196.8524 ]\n",
      " [138.57007]]\n",
      "150 Cost:  7.402026 \n",
      " Prediction: \n",
      " [[155.46255]\n",
      " [181.94438]\n",
      " [181.8802 ]\n",
      " [196.84084]\n",
      " [138.61742]]\n",
      "200 Cost:  7.2085066 \n",
      " Prediction: \n",
      " [[155.41048]\n",
      " [181.98009]\n",
      " [181.86424]\n",
      " [196.82942]\n",
      " [138.66414]]\n",
      "250 Cost:  7.0201693 \n",
      " Prediction: \n",
      " [[155.3591 ]\n",
      " [182.01529]\n",
      " [181.84848]\n",
      " [196.81815]\n",
      " [138.71024]]\n",
      "300 Cost:  6.836871 \n",
      " Prediction: \n",
      " [[155.30841]\n",
      " [182.05002]\n",
      " [181.83293]\n",
      " [196.80704]\n",
      " [138.7557 ]]\n",
      "350 Cost:  6.6584663 \n",
      " Prediction: \n",
      " [[155.25839]\n",
      " [182.08429]\n",
      " [181.8176 ]\n",
      " [196.79607]\n",
      " [138.80055]]\n",
      "400 Cost:  6.484832 \n",
      " Prediction: \n",
      " [[155.20906]\n",
      " [182.11809]\n",
      " [181.80246]\n",
      " [196.78526]\n",
      " [138.84482]]\n",
      "450 Cost:  6.315852 \n",
      " Prediction: \n",
      " [[155.1604 ]\n",
      " [182.15144]\n",
      " [181.78752]\n",
      " [196.77461]\n",
      " [138.88847]]\n",
      "500 Cost:  6.151353 \n",
      " Prediction: \n",
      " [[155.11238]\n",
      " [182.18436]\n",
      " [181.7728 ]\n",
      " [196.76407]\n",
      " [138.93155]]\n",
      "550 Cost:  5.9913 \n",
      " Prediction: \n",
      " [[155.065  ]\n",
      " [182.21681]\n",
      " [181.75826]\n",
      " [196.75371]\n",
      " [138.97401]]\n",
      "600 Cost:  5.8354774 \n",
      " Prediction: \n",
      " [[155.01825]\n",
      " [182.24884]\n",
      " [181.74393]\n",
      " [196.74345]\n",
      " [139.01593]]\n",
      "650 Cost:  5.683838 \n",
      " Prediction: \n",
      " [[154.97215]\n",
      " [182.28044]\n",
      " [181.72978]\n",
      " [196.73338]\n",
      " [139.0573 ]]\n",
      "700 Cost:  5.536242 \n",
      " Prediction: \n",
      " [[154.92665]\n",
      " [182.31161]\n",
      " [181.7158 ]\n",
      " [196.7234 ]\n",
      " [139.09807]]\n",
      "750 Cost:  5.3926206 \n",
      " Prediction: \n",
      " [[154.88179]\n",
      " [182.34236]\n",
      " [181.70204]\n",
      " [196.71358]\n",
      " [139.13832]]\n",
      "800 Cost:  5.252824 \n",
      " Prediction: \n",
      " [[154.83752]\n",
      " [182.37271]\n",
      " [181.68846]\n",
      " [196.7039 ]\n",
      " [139.17802]]\n",
      "850 Cost:  5.116777 \n",
      " Prediction: \n",
      " [[154.79384]\n",
      " [182.40263]\n",
      " [181.67506]\n",
      " [196.69434]\n",
      " [139.21718]]\n",
      "900 Cost:  4.9843435 \n",
      " Prediction: \n",
      " [[154.75075]\n",
      " [182.43216]\n",
      " [181.66182]\n",
      " [196.6849 ]\n",
      " [139.25581]]\n",
      "950 Cost:  4.8554697 \n",
      " Prediction: \n",
      " [[154.70822]\n",
      " [182.46127]\n",
      " [181.64879]\n",
      " [196.6756 ]\n",
      " [139.29393]]\n",
      "1000 Cost:  4.7300024 \n",
      " Prediction: \n",
      " [[154.66629]\n",
      " [182.49004]\n",
      " [181.63591]\n",
      " [196.66643]\n",
      " [139.33154]]\n",
      "1050 Cost:  4.6079636 \n",
      " Prediction: \n",
      " [[154.62491]\n",
      " [182.51837]\n",
      " [181.62323]\n",
      " [196.6574 ]\n",
      " [139.36862]]\n",
      "1100 Cost:  4.4891086 \n",
      " Prediction: \n",
      " [[154.58409]\n",
      " [182.54636]\n",
      " [181.61069]\n",
      " [196.64845]\n",
      " [139.40523]]\n",
      "1150 Cost:  4.3734493 \n",
      " Prediction: \n",
      " [[154.54381]\n",
      " [182.57396]\n",
      " [181.59833]\n",
      " [196.63966]\n",
      " [139.44133]]\n",
      "1200 Cost:  4.260928 \n",
      " Prediction: \n",
      " [[154.50409]\n",
      " [182.60118]\n",
      " [181.58615]\n",
      " [196.631  ]\n",
      " [139.47694]]\n",
      "1250 Cost:  4.15137 \n",
      " Prediction: \n",
      " [[154.46487]\n",
      " [182.62804]\n",
      " [181.57411]\n",
      " [196.62242]\n",
      " [139.51207]]\n",
      "1300 Cost:  4.044757 \n",
      " Prediction: \n",
      " [[154.42621]\n",
      " [182.65453]\n",
      " [181.56224]\n",
      " [196.61397]\n",
      " [139.54674]]\n",
      "1350 Cost:  3.9410005 \n",
      " Prediction: \n",
      " [[154.38808]\n",
      " [182.6807 ]\n",
      " [181.55055]\n",
      " [196.60565]\n",
      " [139.58093]]\n",
      "1400 Cost:  3.8399882 \n",
      " Prediction: \n",
      " [[154.3504 ]\n",
      " [182.70647]\n",
      " [181.53899]\n",
      " [196.59741]\n",
      " [139.61465]]\n",
      "1450 Cost:  3.7417095 \n",
      " Prediction: \n",
      " [[154.3133 ]\n",
      " [182.73192]\n",
      " [181.52759]\n",
      " [196.58931]\n",
      " [139.64793]]\n",
      "1500 Cost:  3.6460361 \n",
      " Prediction: \n",
      " [[154.27664]\n",
      " [182.757  ]\n",
      " [181.51633]\n",
      " [196.5813 ]\n",
      " [139.68076]]\n",
      "1550 Cost:  3.552938 \n",
      " Prediction: \n",
      " [[154.2405 ]\n",
      " [182.78177]\n",
      " [181.50525]\n",
      " [196.57341]\n",
      " [139.71313]]\n",
      "1600 Cost:  3.4623344 \n",
      " Prediction: \n",
      " [[154.20483]\n",
      " [182.80618]\n",
      " [181.49431]\n",
      " [196.56564]\n",
      " [139.74509]]\n",
      "1650 Cost:  3.3741384 \n",
      " Prediction: \n",
      " [[154.16968]\n",
      " [182.83029]\n",
      " [181.4835 ]\n",
      " [196.55795]\n",
      " [139.77661]]\n",
      "1700 Cost:  3.288285 \n",
      " Prediction: \n",
      " [[154.13496]\n",
      " [182.85408]\n",
      " [181.47285]\n",
      " [196.5504 ]\n",
      " [139.80771]]\n",
      "1750 Cost:  3.2047431 \n",
      " Prediction: \n",
      " [[154.10072]\n",
      " [182.87753]\n",
      " [181.46234]\n",
      " [196.54292]\n",
      " [139.83838]]\n",
      "1800 Cost:  3.123426 \n",
      " Prediction: \n",
      " [[154.06694]\n",
      " [182.9007 ]\n",
      " [181.45197]\n",
      " [196.53557]\n",
      " [139.86862]]\n",
      "1850 Cost:  3.0442986 \n",
      " Prediction: \n",
      " [[154.03363]\n",
      " [182.92352]\n",
      " [181.44174]\n",
      " [196.52829]\n",
      " [139.89848]]\n",
      "1900 Cost:  2.967263 \n",
      " Prediction: \n",
      " [[154.00073]\n",
      " [182.94604]\n",
      " [181.43164]\n",
      " [196.52115]\n",
      " [139.92793]]\n",
      "1950 Cost:  2.8923154 \n",
      " Prediction: \n",
      " [[153.9683 ]\n",
      " [182.96826]\n",
      " [181.42169]\n",
      " [196.51407]\n",
      " [139.95699]]\n",
      "2000 Cost:  2.8193574 \n",
      " Prediction: \n",
      " [[153.93631]\n",
      " [182.99019]\n",
      " [181.41187]\n",
      " [196.5071 ]\n",
      " [139.98564]]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    cost_val, h_val, _ = sess.run([cost, h, train], feed_dict={X: x_data, Y:y_data})\n",
    "    if step % 50 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\n Prediction: \\n\", h_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning rate 을 0.01 로 조정  \n",
    "- nan 값이 출력 \n",
    "- learning rate 을 더 작게 할 필요가 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "50 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "100 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "150 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "200 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "250 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "300 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "350 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "400 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "450 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "500 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "550 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "600 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "650 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "700 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "750 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "800 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "850 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "900 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "950 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1000 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1050 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1100 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1150 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1200 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1250 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1300 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1350 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1400 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1450 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1500 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1550 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1600 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1650 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1700 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1750 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1800 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1850 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1900 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1950 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "2000 Cost:  nan \n",
      " Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "h = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(h - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, h_val, _ = sess.run([cost, h, train], feed_dict={X: x_data, Y:y_data})\n",
    "    if step % 50 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\n Prediction: \\n\", h_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
