{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 구현\n",
    "- Data set : MNIST\n",
    "    - tensorflow input_data 가 deprecated 되어 keras 의 data set 으로 가져옴\n",
    "- Split Train set and Validation set for checking overfit \n",
    "- Normalize image data (0-255) to (0-1) \n",
    "    - x / 255 \n",
    "- One-hot encoding \n",
    "    - keras \n",
    "    - pandas : get_dummies\n",
    "    - scikit-learn \n",
    "- Model \n",
    "    - Hypothesis : softmax \n",
    "    - Cost : Cross-entropy \n",
    "    - Optimizer = Adam optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deprecated \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "mnist.train.num_examples # 60000\n",
    "mnist.test.num_examples # 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: 60000, test set:10000\n"
     ]
    }
   ],
   "source": [
    "print('train set: {0}, test set:{1}'.format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Shape] X: (60000, 28, 28), Y: (60000,)\n"
     ]
    }
   ],
   "source": [
    "print('[Shape] X: {0}, Y: {1}'.format(x_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f848a8e550>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train data and validation data\n",
    "- validation data\n",
    "    * train data 로 학습된 모델의 성능을 평가하기 위해서 사용 \n",
    "    * 규제 기법 중 하나인 조기멈춤에 활용할 수 있다. (overcome overfitting )\n",
    "- 6만개의 train set 에서 1만개의 validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train data , validation data among x_train\n",
    "x_val = x_train[50000:60000]\n",
    "x_train = x_train[0:50000]\n",
    "y_val = y_train[50000:60000]\n",
    "y_train = y_train[0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 50000, validation size: 10000\n"
     ]
    }
   ],
   "source": [
    "# 확인!\n",
    "print('train size: {0}, validation size: {1}'.format(len(x_train), len(x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape  \n",
    "- Reshape matrix to array for using input data\n",
    "-  28 * 28 (matrix) --> 784 (series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(50000, 784) \n",
    "x_val = x_val.reshape(10000, 784)\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Shape] x_train shape : (50000, 784), x_test shape :(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print('[Shape] x_train shape : {0}, x_test shape :{1}'.format(x_train.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data\n",
    "- 0 - 255 : 흰색 부터 검은색까지 scale 값\n",
    "- x / 255 --> 0 ~ 1 : variance를 줄여줌으로써 학습속도도 빨라지고 accuracy 도 올라가는 경향 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "gray_scale = 255\n",
    "x_train /= gray_scale\n",
    "x_val /= gray_scale\n",
    "x_test /= gray_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label to one hot Encoding value\n",
    "- method\n",
    "    - keras\n",
    "    - scikit-learn\n",
    "    - pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras one-hot encoding \n",
    "num_class = 10\n",
    "keras_y_train = tf.keras.utils.to_categorical(y_train, num_class)\n",
    "keras_y_val = tf.keras.utils.to_categorical(y_val, num_class)\n",
    "keras_y_test = tf.keras.utils.to_categorical(y_test, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Shape] \n",
      " one-hot 전 shpae: (50000,) \n",
      " 5,\n",
      " one-hot 후 shape : (50000, 10) \n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('[Shape] \\n one-hot 전 shpae: {0} \\n {1},\\n one-hot 후 shape : {2} \\n {3}'\n",
    "      .format(y_train.shape, y_train[0], keras_y_train.shape ,keras_y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas one-hot encoding\n",
    "pan_y_train = pd.get_dummies(y_train)\n",
    "pan_y_val = pd.get_dummies(y_val)\n",
    "pan_y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Shape] \n",
      " one-hot 전 shpae: (50000,) \n",
      " 5,\n",
      " one-hot 후 shape : (50000, 10) \n",
      " 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    1\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "Name: 0, dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "print('[Shape] \\n one-hot 전 shpae: {0} \\n {1},\\n one-hot 후 shape : {2} \\n {3}'\n",
    "      .format(y_train.shape, y_train[0], pan_y_train.shape ,pan_y_train.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape for using scikit-learn OneHotEncoder \n",
    "rsp_y_train = y_train.reshape(-1, 1)\n",
    "rsp_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn one-hot encoding\n",
    "ohe = OneHotEncoder()\n",
    "skl_y_train = ohe.fit_transform(rsp_y_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Shape] \n",
      " one-hot 전 shpae: (50000,) \n",
      " 5,\n",
      " one-hot 후 shape : (50000, 10) \n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('[Shape] \\n one-hot 전 shpae: {0} \\n {1},\\n one-hot 후 shape : {2} \\n {3}'\n",
    "      .format(y_train.shape, y_train[0], skl_y_train.shape ,skl_y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow MLP Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 10\n",
    "X = tf.placeholder(tf.float32, [None, 784]) # 28 * 28 \n",
    "Y = tf.placeholder(tf.float32, [None, num_class]) # 10개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x):\n",
    "    # hidden layer 1\n",
    "    W1 = tf.Variable(tf.random_uniform([784, 256]))\n",
    "    b1 = tf.Variable(tf.zeros([256]))\n",
    "    h1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "    \n",
    "    # hidden layer 2\n",
    "    W2 = tf.Variable(tf.random_uniform([256, 128]))\n",
    "    b2 = tf.Variable(tf.zeros([128]))\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, W2) + b2)\n",
    "    \n",
    "    # output layer \n",
    "    W3 = tf.Variable(tf.random_uniform([128 ,10]))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "    logits = tf.matmul(h2, W3) + b3\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis = logits \n",
    "logits = mlp(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction 함수인 softmax 와 실제 y 의 오차 \n",
    "cost_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost 를 줄이는 방향으로 계속 학습 \n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train hyperparameter \n",
    "epoch_cnt = 20 # 전체 데이터 20번 학습 \n",
    "batch_size = 1000\n",
    "# 50000 // 1000 = 50 : 전체 데이터를 50개로 나눠서 실행 \n",
    "iteration = len(x_train) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch >> 0 \n",
      " Validation ACC: 0.1826000064611435 \n",
      " cost: 7889.600847778325\n",
      "Epoch >> 1 \n",
      " Validation ACC: 0.7907000184059143 \n",
      " cost: 258.28172824859627\n",
      "Epoch >> 2 \n",
      " Validation ACC: 0.8787000179290771 \n",
      " cost: 17.215058269500734\n",
      "Epoch >> 3 \n",
      " Validation ACC: 0.8853999972343445 \n",
      " cost: 10.820834321975708\n",
      "Epoch >> 4 \n",
      " Validation ACC: 0.8840000033378601 \n",
      " cost: 9.070477018356325\n",
      "Epoch >> 5 \n",
      " Validation ACC: 0.8842999935150146 \n",
      " cost: 8.17855834007263\n",
      "Epoch >> 6 \n",
      " Validation ACC: 0.8942999839782715 \n",
      " cost: 7.054223055839537\n",
      "Epoch >> 7 \n",
      " Validation ACC: 0.878600001335144 \n",
      " cost: 8.653544282913206\n",
      "Epoch >> 8 \n",
      " Validation ACC: 0.9049999713897705 \n",
      " cost: 7.352967267036438\n",
      "Epoch >> 9 \n",
      " Validation ACC: 0.9157000184059143 \n",
      " cost: 7.151118326187133\n",
      "Epoch >> 10 \n",
      " Validation ACC: 0.8964999914169312 \n",
      " cost: 5.814308238029481\n",
      "Epoch >> 11 \n",
      " Validation ACC: 0.8906999826431274 \n",
      " cost: 4.982299079895021\n",
      "Epoch >> 12 \n",
      " Validation ACC: 0.8235999941825867 \n",
      " cost: 46.01525740146636\n",
      "Epoch >> 13 \n",
      " Validation ACC: 0.9120000004768372 \n",
      " cost: 9.568652610778807\n",
      "Epoch >> 14 \n",
      " Validation ACC: 0.9089000225067139 \n",
      " cost: 6.273658504486085\n",
      "Epoch >> 15 \n",
      " Validation ACC: 0.9136999845504761 \n",
      " cost: 5.359600973129273\n",
      "Epoch >> 16 \n",
      " Validation ACC: 0.9133999943733215 \n",
      " cost: 4.900627365112305\n",
      "Epoch >> 17 \n",
      " Validation ACC: 0.8925999999046326 \n",
      " cost: 4.899594931602477\n",
      "Epoch >> 18 \n",
      " Validation ACC: 0.8543999791145325 \n",
      " cost: 6.369704113006593\n",
      "Epoch >> 19 \n",
      " Validation ACC: 0.9135000109672546 \n",
      " cost: 5.526088142395019\n",
      "[Test Accuracy] 0.9125999808311462\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epoch_cnt):\n",
    "        avg_loss = 0\n",
    "        start =0\n",
    "        end = batch_size # 1000\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            _, cost = sess.run([train_op, cost_op],\n",
    "                                  feed_dict = {X:x_train[start:end], Y:keras_y_train[start:end]})\n",
    "            start += batch_size\n",
    "            end += batch_size\n",
    "            avg_loss += cost / iteration\n",
    "            \n",
    "        # validate model\n",
    "        h = tf.nn.softmax(logits)\n",
    "        is_correct = tf.equal(tf.argmax(h, axis=1), tf.argmax(Y, axis=1))\n",
    "        # calculate acc \n",
    "        accuracy = tf.reduce_mean(tf.cast(is_correct, \"float\"))\n",
    "        cur_val_acc = accuracy.eval({X:x_val, Y:keras_y_val})\n",
    "        print(\"Epoch >> {0} \\n Validation ACC: {1} \\n cost: {2}\".format(\n",
    "                epoch, cur_val_acc, avg_loss))\n",
    "    \n",
    "    # Test model\n",
    "    h = tf.nn.softmax(logits)\n",
    "    is_correct = tf.equal(tf.argmax(h, axis=1), tf.argmax(Y, axis=1))\n",
    "    # calculate acc \n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, \"float\"))\n",
    "    print('[Test Accuracy] {0}'.format(accuracy.eval({X:x_test, Y:keras_y_test})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch >> 0 \n",
      " Validation ACC: 0.22269999980926514 \n",
      " cost: 1182.500732421875\n",
      "Epoch >> 1 \n",
      " Validation ACC: 0.742900013923645 \n",
      " cost: 29.421234130859375\n",
      "Epoch >> 2 \n",
      " Validation ACC: 0.8751999735832214 \n",
      " cost: 11.128425598144531\n",
      "Epoch >> 3 \n",
      " Validation ACC: 0.8873000144958496 \n",
      " cost: 8.047269821166992\n",
      "Epoch >> 4 \n",
      " Validation ACC: 0.8952000141143799 \n",
      " cost: 6.3472771644592285\n",
      "Epoch >> 5 \n",
      " Validation ACC: 0.9010000228881836 \n",
      " cost: 4.90213680267334\n",
      "Epoch >> 6 \n",
      " Validation ACC: 0.9064000248908997 \n",
      " cost: 3.9920904636383057\n",
      "Epoch >> 7 \n",
      " Validation ACC: 0.9079999923706055 \n",
      " cost: 3.459986686706543\n",
      "Epoch >> 8 \n",
      " Validation ACC: 0.9067999720573425 \n",
      " cost: 3.153001546859741\n",
      "Epoch >> 9 \n",
      " Validation ACC: 0.8999000191688538 \n",
      " cost: 3.1492342948913574\n",
      "Epoch >> 10 \n",
      " Validation ACC: 0.8991000056266785 \n",
      " cost: 2.8083465099334717\n",
      "Epoch >> 11 \n",
      " Validation ACC: 0.9096999764442444 \n",
      " cost: 2.5200512409210205\n",
      "Epoch >> 12 \n",
      " Validation ACC: 0.9053999781608582 \n",
      " cost: 2.662661552429199\n",
      "Epoch >> 13 \n",
      " Validation ACC: 0.9088000059127808 \n",
      " cost: 2.495192527770996\n",
      "Epoch >> 14 \n",
      " Validation ACC: 0.9063000082969666 \n",
      " cost: 2.2312583923339844\n",
      "Epoch >> 15 \n",
      " Validation ACC: 0.8974000215530396 \n",
      " cost: 2.0784592628479004\n",
      "Epoch >> 16 \n",
      " Validation ACC: 0.9049999713897705 \n",
      " cost: 2.3639748096466064\n",
      "Epoch >> 17 \n",
      " Validation ACC: 0.8668000102043152 \n",
      " cost: 2.2033448219299316\n",
      "Epoch >> 18 \n",
      " Validation ACC: 0.923799991607666 \n",
      " cost: 1.955889105796814\n",
      "Epoch >> 19 \n",
      " Validation ACC: 0.907800018787384 \n",
      " cost: 2.0181679725646973\n",
      "[Test Accuracy] 0.9106000065803528\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epoch_cnt):\n",
    "        avg_loss = 0\n",
    "        start =0\n",
    "        end = batch_size # 1000\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            _, cost = sess.run([train_op, cost_op],\n",
    "                                  feed_dict = {X:x_train[start:end], Y:keras_y_train[start:end]})\n",
    "            start += batch_size\n",
    "            end += batch_size\n",
    "            avg_loss = cost\n",
    "            \n",
    "        # validate model\n",
    "        h = tf.nn.softmax(logits)\n",
    "        is_correct = tf.equal(tf.argmax(h, axis=1), tf.argmax(Y, axis=1))\n",
    "        # calculate acc \n",
    "        accuracy = tf.reduce_mean(tf.cast(is_correct, \"float\"))\n",
    "        cur_val_acc = accuracy.eval({X:x_val, Y:keras_y_val})\n",
    "        print(\"Epoch >> {0} \\n Validation ACC: {1} \\n cost: {2}\".format(\n",
    "                epoch, cur_val_acc, avg_loss))\n",
    "    \n",
    "    # Test \n",
    "    h = tf.nn.softmax(logits)\n",
    "    is_correct = tf.equal(tf.argmax(h, axis=1), tf.argmax(Y, axis=1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, \"float\"))\n",
    "    print('[Test Accuracy] {0}'.format(accuracy.eval({X:x_test, Y:keras_y_test})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
