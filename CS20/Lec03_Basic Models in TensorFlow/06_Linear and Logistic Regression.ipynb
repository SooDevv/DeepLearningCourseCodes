{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Models in TensorFlow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with ce loss\n",
    "- Dataset: MNIST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Pre-process data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_tst, y_tst) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train/255 # Normalization\n",
    "x_train = x_train.reshape(-1, 784) # 2D --> 1D\n",
    "x_tst = x_tst/255\n",
    "x_tst = x_tst.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (60000, 784) \n",
      "y_train.shape: (60000,)\n",
      "x_tst.shape: (10000, 784) \n",
      "y_tst.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train.shape: {} \\ny_train.shape: {}'.format(x_train.shape, y_train.shape))\n",
    "print('x_tst.shape: {} \\ny_tst.shape: {}'.format(x_tst.shape, y_tst.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_tr.shape: (55000, 784) \n",
      "y_tr.shape: (55000,)\n",
      "x_val.shape: (5000, 784) \n",
      "y_val.shape: (5000,)\n"
     ]
    }
   ],
   "source": [
    "tr_indices = np.random.choice(range(x_train.shape[0]), size=55000, replace=False)\n",
    "\n",
    "x_tr = x_train[tr_indices]\n",
    "y_tr = y_train[tr_indices]\n",
    "\n",
    "# x_train중에서 random값으로 뽑은 tr_indices값을 행(axis=0)을 기준으로 delete\n",
    "x_val = np.delete(arr=x_train, obj=tr_indices, axis=0)\n",
    "y_val = np.delete(arr=y_train, obj=tr_indices, axis=0)\n",
    "\n",
    "print('x_tr.shape: {} \\ny_tr.shape: {}'.format(x_tr.shape, y_tr.shape))\n",
    "print('x_val.shape: {} \\ny_val.shape: {}'.format(x_val.shape, y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the graph of Softmax Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(x_tr.dtype)\n",
    "print(y_tr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create placeholders for x(birth rate) and y(life expectancy)\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(dtype=tf.int32, shape=[None])\n",
    "\n",
    "# Create weight and bias, initialized to 0\n",
    "w = tf.get_variable(name='weights', shape=[784, 10], dtype=tf.float32,\n",
    "                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.get_variable(name='bias', shape=[10], dtype=tf.float32,\n",
    "                   initializer=tf.zeros_initializer())\n",
    "\n",
    "# Construct model \n",
    "score = tf.matmul(x, w) + b\n",
    "\n",
    "# Use the cross entropy as loss function\n",
    "ce_loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=y, logits=score))\n",
    "ce_loss_summ = tf.summary.scalar(name='ce_loss', tensor=ce_loss) # for tensorboard\n",
    "\n",
    "# Using gradient descent with learning rate of 0.01 to minimize loss\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=.01)\n",
    "training_op = opt.minimize(ce_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 64\n",
    "total_step = int(x_tr.shape[0]/batch_size)\n",
    "print(total_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For using tensorboard \n",
    "train_writer = tf.summary.FileWriter(logdir='../graphs/lec03/logreg_tf_placholder/train',\n",
    "                                    graph=tf.get_default_graph())\n",
    "val_writer = tf.summary.FileWriter(logdir='../graphs/lec03/logreg_tf_placeholder/val',\n",
    "                                  graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   5, tr_loss: 0.42, val_loss: 0.36\n",
      "epoch:  10, tr_loss: 0.36, val_loss: 0.30\n",
      "epoch:  15, tr_loss: 0.34, val_loss: 0.27\n",
      "epoch:  20, tr_loss: 0.33, val_loss: 0.26\n",
      "epoch:  25, tr_loss: 0.31, val_loss: 0.25\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "tr_loss_hist = []\n",
    "val_loss_hist = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_tr_loss = 0\n",
    "    avg_val_loss = 0\n",
    "    \n",
    "    for step in range(total_step):\n",
    "        \n",
    "        batch_indices = np.random.choice(range(x_tr.shape[0]), size=batch_size, replace=False)\n",
    "        val_indices - np.random.choice(range(x_val.shape[0]), size=batch_size, replace=False)\n",
    "        \n",
    "        batch_xs = x_tr[batch_indices]\n",
    "        batch_ys = y_tr[batch_indices]\n",
    "        val_xs = x_val[val_indices]\n",
    "        val_ys = y_val[val_indices]\n",
    "        \n",
    "        _, tr_loss = sess.run(fetches=[training_op, ce_loss],\n",
    "                        feed_dict={x: batch_xs, y: batch_ys})\n",
    "        tr_loss_summ = sess.run(ce_loss_summ, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        \n",
    "        val_loss, val_loss_summ = sess.run(fetches=[ce_loss, ce_loss_summ],\n",
    "                                          feed_dict={x: val_xs, y:val_ys})\n",
    "        avg_tr_loss += tr_loss / total_step\n",
    "        avg_val_loss += val_loss / total_step\n",
    "        \n",
    "    tr_loss_hist.append(avg_tr_loss)\n",
    "    val_loss_hist.append(avg_val_loss)\n",
    "    train_writer.add_summary(tr_loss_summ, global_step=epoch)\n",
    "    val_writer.add_summary(val_loss_summ, global_step=epoch)\n",
    "    \n",
    "    if(epoch + 1) % 5 == 0:\n",
    "        print('epoch: {:3}, tr_loss: {:.2f}, val_loss: {:.2f}'.format(epoch+1, avg_tr_loss, avg_val_loss))\n",
    "\n",
    "train_writer.close()\n",
    "val_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tr_loss_hist, label='train')\n",
    "plt.plot(val_loss_hist, label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.argmax(sess.run(score, feed_dict={X: x_tst}), axis=1)\n",
    "print('acc: {:.2%}'.format(np.mean(yhat == y_tst)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
