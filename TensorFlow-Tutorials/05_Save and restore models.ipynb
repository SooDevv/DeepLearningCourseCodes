{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and restore models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q h5py pyyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an example dataset \n",
    "- Data set: MNIST\n",
    "- 1000examples to speed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "#normalization \n",
    "train_images = train_images[:1000].reshape(-1, 28*28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28*28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a short sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)), #input image = 28*28\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax) #fc-layer\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "                  loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create a basic model instance\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save checkpoints during training \n",
    "- ModelCheckpoint: use a trained model without retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 1.1317 - acc: 0.6948\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 1s 753us/step - loss: 1.1083 - acc: 0.7000 - val_loss: 0.6781 - val_acc: 0.7960\n",
      "Epoch 2/10\n",
      " 864/1000 [========================>.....] - ETA: 0s - loss: 0.4205 - acc: 0.8912\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 397us/step - loss: 0.4125 - acc: 0.8950 - val_loss: 0.5518 - val_acc: 0.8260\n",
      "Epoch 3/10\n",
      " 800/1000 [=======================>......] - ETA: 0s - loss: 0.2945 - acc: 0.9237\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 402us/step - loss: 0.2833 - acc: 0.9280 - val_loss: 0.4865 - val_acc: 0.8410\n",
      "Epoch 4/10\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 0.1998 - acc: 0.9583\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 397us/step - loss: 0.1980 - acc: 0.9590 - val_loss: 0.4453 - val_acc: 0.8480\n",
      "Epoch 5/10\n",
      " 896/1000 [=========================>....] - ETA: 0s - loss: 0.1540 - acc: 0.9676\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 402us/step - loss: 0.1503 - acc: 0.9690 - val_loss: 0.4315 - val_acc: 0.8600\n",
      "Epoch 6/10\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 0.1072 - acc: 0.9833\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 403us/step - loss: 0.1072 - acc: 0.9830 - val_loss: 0.4298 - val_acc: 0.8630\n",
      "Epoch 7/10\n",
      " 512/1000 [==============>...............] - ETA: 0s - loss: 0.0778 - acc: 0.9941\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 387us/step - loss: 0.0795 - acc: 0.9920 - val_loss: 0.4393 - val_acc: 0.8600\n",
      "Epoch 8/10\n",
      " 832/1000 [=======================>......] - ETA: 0s - loss: 0.0687 - acc: 0.9928\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 419us/step - loss: 0.0656 - acc: 0.9940 - val_loss: 0.4086 - val_acc: 0.8650\n",
      "Epoch 9/10\n",
      " 800/1000 [=======================>......] - ETA: 0s - loss: 0.0481 - acc: 0.9988\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 410us/step - loss: 0.0447 - acc: 0.9980 - val_loss: 0.4312 - val_acc: 0.8600\n",
      "Epoch 10/10\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9990\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 401us/step - loss: 0.0397 - acc: 0.9990 - val_loss: 0.4294 - val_acc: 0.8630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x255915814e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "cheeckpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                save_weights_only=True,\n",
    "                                                verbose=1)\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=10,\n",
    "         validation_data= (test_images, test_labels),\n",
    "         callbacks = [cp_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\n",
      "cp.ckpt.data-00000-of-00001\n",
      "cp.ckpt.index\n"
     ]
    }
   ],
   "source": [
    "!ls {cheeckpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 136us/step\n",
      "Untrained model, accuracy:  6.00%\n"
     ]
    }
   ],
   "source": [
    "# 모델 새로 생성하고 model을 restore하려면 동일한 모델 아키텍처\n",
    "# model architecture가 같다면 we can share weights despite that it's a different instance of the model \n",
    "model = create_model()\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 55us/step\n",
      "Restored model, accuracy: 86.30%\n"
     ]
    }
   ],
   "source": [
    "# load_weights : Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
    "# load the weights from the checkpoint \n",
    "model.load_weights(checkpoint_path)\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint callback options \n",
    "- Train a new model, and save uniquely named checkpoints once every 5-epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
      "\n",
      "Epoch 00010: saving model to training_2/cp-0010.ckpt\n",
      "\n",
      "Epoch 00015: saving model to training_2/cp-0015.ckpt\n",
      "\n",
      "Epoch 00020: saving model to training_2/cp-0020.ckpt\n",
      "\n",
      "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
      "\n",
      "Epoch 00030: saving model to training_2/cp-0030.ckpt\n",
      "\n",
      "Epoch 00035: saving model to training_2/cp-0035.ckpt\n",
      "\n",
      "Epoch 00040: saving model to training_2/cp-0040.ckpt\n",
      "\n",
      "Epoch 00045: saving model to training_2/cp-0045.ckpt\n",
      "\n",
      "Epoch 00050: saving model to training_2/cp-0050.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25591581518>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "cheeckpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_weights_only=True,\n",
    "    # Save weights, every 5-epochs.\n",
    "    period=5)\n",
    "\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels,\n",
    "         epochs=50, callbacks = [cp_callback],\n",
    "         validation_data = (test_images, test_labels),\n",
    "         verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\n",
      "cp-0005.ckpt.data-00000-of-00001\n",
      "cp-0005.ckpt.index\n",
      "cp-0010.ckpt.data-00000-of-00001\n",
      "cp-0010.ckpt.index\n",
      "cp-0015.ckpt.data-00000-of-00001\n",
      "cp-0015.ckpt.index\n",
      "cp-0020.ckpt.data-00000-of-00001\n",
      "cp-0020.ckpt.index\n",
      "cp-0025.ckpt.data-00000-of-00001\n",
      "cp-0025.ckpt.index\n",
      "cp-0030.ckpt.data-00000-of-00001\n",
      "cp-0030.ckpt.index\n",
      "cp-0035.ckpt.data-00000-of-00001\n",
      "cp-0035.ckpt.index\n",
      "cp-0040.ckpt.data-00000-of-00001\n",
      "cp-0040.ckpt.index\n",
      "cp-0045.ckpt.data-00000-of-00001\n",
      "cp-0045.ckpt.index\n",
      "cp-0050.ckpt.data-00000-of-00001\n",
      "cp-0050.ckpt.index\n"
     ]
    }
   ],
   "source": [
    "!ls {cheeckpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_2\\\\cp-0050.ckpt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(cheeckpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 111us/step\n",
      "Restored model, accuracy: 88.00%.\n"
     ]
    }
   ],
   "source": [
    "#test,reset the model and load the latest checkpoint\n",
    "model = create_model()\n",
    "model.load_weights(latest)\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%.\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: saving model to training_3/cp-0005.ckpt\n",
      "\n",
      "Epoch 00010: saving model to training_3/cp-0010.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25593757b70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_3/cp-{epoch:04d}.ckpt\"\n",
    "cheeckpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_weights_only=True,\n",
    "    # Save weights, every 5-epochs.\n",
    "    period=5)\n",
    "\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels,\n",
    "         epochs=10, callbacks = [cp_callback],\n",
    "         validation_data = (test_images, test_labels),\n",
    "         verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_3\\\\cp-0010.ckpt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(cheeckpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 126us/step\n",
      "Restored model, accuracy: 86.70%.\n"
     ]
    }
   ],
   "source": [
    "#test,reset the model and load the latest checkpoint\n",
    "model = create_model()\n",
    "model.load_weights(latest)\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%.\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually save weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights \n",
    "model.save_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 156us/step\n",
      "Restored model, accuracy: 86.70%\n"
     ]
    }
   ],
   "source": [
    "# Restore the weights \n",
    "model = create_model()\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the entire model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 613us/step - loss: 1.1430 - acc: 0.6870\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 217us/step - loss: 0.4089 - acc: 0.8930\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 211us/step - loss: 0.2737 - acc: 0.9300\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 212us/step - loss: 0.2062 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 201us/step - loss: 0.1555 - acc: 0.9700\n"
     ]
    }
   ],
   "source": [
    "# HDF5 file\n",
    "model = create_model()\n",
    "\n",
    "#keras의 compile로 model save. `tf.train'으로는 tensorflow optimizers를 저장할 수 없다\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "             loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# Save entire model to a HDF5 file\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including weights and optimizer \n",
    "new_model = keras.models.load_model('my_model.h5')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 167us/step\n",
      "Restored model, accuracy: 86.30%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As a saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 502us/step - loss: 1.1482 - acc: 0.6780\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 124us/step - loss: 0.4252 - acc: 0.8770\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 121us/step - loss: 0.2900 - acc: 0.9220\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 146us/step - loss: 0.2062 - acc: 0.9570\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 116us/step - loss: 0.1533 - acc: 0.9680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x255999a6f98>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: saved_models\\temp-b'1542873356'\\saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = tf.contrib.saved_model.save_keras_model(model, 'saved_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1542873356\n"
     ]
    }
   ],
   "source": [
    "!ls saved_models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x255a0f03710>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = tf.contrib.saved_model.load_keras_model(saved_model_path)\n",
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 220us/step\n",
      "Restored model, accuracy: 86.30%\n"
     ]
    }
   ],
   "source": [
    "# Run the restored model \n",
    "# The optimizer was not restored, re-attach a new one\n",
    "new_model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "                 loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "loss, acc = new_model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
