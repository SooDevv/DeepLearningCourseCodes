{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting and underfitting \n",
    "- IMDB Dataset\n",
    "- Overfitting \n",
    "    + baseline model\n",
    "    + smaller model \n",
    "    + bigger model \n",
    "    + plot the trainig and validation loss\n",
    "- Strategies\n",
    "    + weight regularization \n",
    "    + dropout   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting \n",
    "- Intuitively, a model with more parameters will have more **memorization capacity** 그래서 training set을 퍼펙하게 외워버림. 일반화시키는게 아니라. 이러면 unseen data인 test set에 대하여 모델이 아무 쓸모가 없음\n",
    "- **Deep learning models tend to be good at fitting to the training data, but the real challenge is generalization, not fitting**\n",
    "- If you train for too long though, the model will start to overfit and learn patterns from the training data that don't generalize to the test data.\n",
    "\n",
    "**Solution**\n",
    "- more training data \n",
    "- regularization \n",
    "    + weight regularization \n",
    "    + dropout \n",
    "\n",
    "### Underfitting \n",
    "- model is not powerful enough, is over-regularized, or has simply not been trained long enough. This means the network has not learned the relevant patterns in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the IMDB dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = 10000\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=NUM_WORDS)\n",
    "\n",
    "def multi_hot_sequences(sequences, dimension):\n",
    "    results = np.zeros((len(sequences), dimension)) #len(sequence)행, dimension열의 0행렬 \n",
    "    for i, word_indices in enumerate(sequences):\n",
    "        results[i, word_indices] = 1.0 # 각 단어마다 one-hot encoding \n",
    "    return results\n",
    "\n",
    "train_data = multi_hot_sequences(train_data, dimension=NUM_WORDS)\n",
    "test_data = multi_hot_sequences(test_data, dimension=NUM_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a7b05e25c0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_data[0]) #muliti-hot encoding 결과인데 0이 월등히 많으므로 plot이 아래와같이 나옴 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a baseline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                160016    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,305\n",
      "Trainable params: 160,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_model = keras.Sequential([\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu, input_shape=(NUM_WORDS,)), #16x10000 + 16x1\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu), #16x16 + 16x1\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid) #16x1 + 1\n",
    "])\n",
    "\n",
    "baseline_model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      " - 9s - loss: 0.5023 - acc: 0.7966 - binary_crossentropy: 0.5023 - val_loss: 0.3480 - val_acc: 0.8709 - val_binary_crossentropy: 0.3480\n",
      "Epoch 2/20\n",
      " - 8s - loss: 0.2574 - acc: 0.9096 - binary_crossentropy: 0.2574 - val_loss: 0.2863 - val_acc: 0.8865 - val_binary_crossentropy: 0.2863\n",
      "Epoch 3/20\n",
      " - 7s - loss: 0.1888 - acc: 0.9334 - binary_crossentropy: 0.1888 - val_loss: 0.2871 - val_acc: 0.8854 - val_binary_crossentropy: 0.2871\n",
      "Epoch 4/20\n",
      " - 8s - loss: 0.1503 - acc: 0.9489 - binary_crossentropy: 0.1503 - val_loss: 0.3087 - val_acc: 0.8789 - val_binary_crossentropy: 0.3087\n",
      "Epoch 5/20\n",
      " - 8s - loss: 0.1228 - acc: 0.9591 - binary_crossentropy: 0.1228 - val_loss: 0.3335 - val_acc: 0.8744 - val_binary_crossentropy: 0.3335\n",
      "Epoch 6/20\n",
      " - 7s - loss: 0.0998 - acc: 0.9692 - binary_crossentropy: 0.0998 - val_loss: 0.3641 - val_acc: 0.8707 - val_binary_crossentropy: 0.3641\n",
      "Epoch 7/20\n",
      " - 7s - loss: 0.0799 - acc: 0.9772 - binary_crossentropy: 0.0799 - val_loss: 0.4189 - val_acc: 0.8622 - val_binary_crossentropy: 0.4189\n",
      "Epoch 8/20\n",
      " - 8s - loss: 0.0632 - acc: 0.9834 - binary_crossentropy: 0.0632 - val_loss: 0.4402 - val_acc: 0.8639 - val_binary_crossentropy: 0.4402\n",
      "Epoch 9/20\n",
      " - 8s - loss: 0.0485 - acc: 0.9890 - binary_crossentropy: 0.0485 - val_loss: 0.4850 - val_acc: 0.8610 - val_binary_crossentropy: 0.4850\n",
      "Epoch 10/20\n",
      " - 7s - loss: 0.0361 - acc: 0.9936 - binary_crossentropy: 0.0361 - val_loss: 0.5332 - val_acc: 0.8577 - val_binary_crossentropy: 0.5332\n",
      "Epoch 11/20\n",
      " - 7s - loss: 0.0266 - acc: 0.9965 - binary_crossentropy: 0.0266 - val_loss: 0.5717 - val_acc: 0.8580 - val_binary_crossentropy: 0.5717\n",
      "Epoch 12/20\n",
      " - 7s - loss: 0.0192 - acc: 0.9980 - binary_crossentropy: 0.0192 - val_loss: 0.6164 - val_acc: 0.8567 - val_binary_crossentropy: 0.6164\n",
      "Epoch 13/20\n",
      " - 7s - loss: 0.0137 - acc: 0.9988 - binary_crossentropy: 0.0137 - val_loss: 0.6551 - val_acc: 0.8560 - val_binary_crossentropy: 0.6551\n",
      "Epoch 14/20\n",
      " - 7s - loss: 0.0100 - acc: 0.9995 - binary_crossentropy: 0.0100 - val_loss: 0.6951 - val_acc: 0.8557 - val_binary_crossentropy: 0.6951\n",
      "Epoch 15/20\n",
      " - 7s - loss: 0.0073 - acc: 0.9998 - binary_crossentropy: 0.0073 - val_loss: 0.7268 - val_acc: 0.8554 - val_binary_crossentropy: 0.7268\n",
      "Epoch 16/20\n",
      " - 7s - loss: 0.0056 - acc: 0.9998 - binary_crossentropy: 0.0056 - val_loss: 0.7563 - val_acc: 0.8546 - val_binary_crossentropy: 0.7563\n",
      "Epoch 17/20\n",
      " - 7s - loss: 0.0044 - acc: 1.0000 - binary_crossentropy: 0.0044 - val_loss: 0.7819 - val_acc: 0.8545 - val_binary_crossentropy: 0.7819\n",
      "Epoch 18/20\n",
      " - 7s - loss: 0.0035 - acc: 1.0000 - binary_crossentropy: 0.0035 - val_loss: 0.8107 - val_acc: 0.8541 - val_binary_crossentropy: 0.8107\n",
      "Epoch 19/20\n",
      " - 7s - loss: 0.0029 - acc: 1.0000 - binary_crossentropy: 0.0029 - val_loss: 0.8298 - val_acc: 0.8548 - val_binary_crossentropy: 0.8298\n",
      "Epoch 20/20\n",
      " - 7s - loss: 0.0024 - acc: 1.0000 - binary_crossentropy: 0.0024 - val_loss: 0.8527 - val_acc: 0.8542 - val_binary_crossentropy: 0.8527\n"
     ]
    }
   ],
   "source": [
    "baseline_history = baseline_model.fit(train_data,\n",
    "                                     train_labels,\n",
    "                                     epochs=20,\n",
    "                                     batch_size=512,\n",
    "                                     validation_data=(test_data, test_labels),\n",
    "                                     verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a smaller model \n",
    "- less hidden units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 4)                 40004     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 40,029\n",
      "Trainable params: 40,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "smaller_model = keras.Sequential([\n",
    "    keras.layers.Dense(4, activation=tf.nn.relu, input_shape=(NUM_WORDS,)), # 4x10000 + 4x1\n",
    "    keras.layers.Dense(4, activation=tf.nn.relu), # 4x4 + 4x1\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid) #4x1 + 1\n",
    "])\n",
    "\n",
    "smaller_model.compile(optimizer='adam',\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "smaller_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      " - 9s - loss: 0.6429 - acc: 0.6414 - binary_crossentropy: 0.6429 - val_loss: 0.5570 - val_acc: 0.7736 - val_binary_crossentropy: 0.5570\n",
      "Epoch 2/20\n",
      " - 7s - loss: 0.4989 - acc: 0.8473 - binary_crossentropy: 0.4989 - val_loss: 0.4942 - val_acc: 0.8405 - val_binary_crossentropy: 0.4942\n",
      "Epoch 3/20\n",
      " - 7s - loss: 0.4405 - acc: 0.8972 - binary_crossentropy: 0.4405 - val_loss: 0.4677 - val_acc: 0.8727 - val_binary_crossentropy: 0.4677\n",
      "Epoch 4/20\n",
      " - 7s - loss: 0.4045 - acc: 0.9205 - binary_crossentropy: 0.4045 - val_loss: 0.4540 - val_acc: 0.8774 - val_binary_crossentropy: 0.4540\n",
      "Epoch 5/20\n",
      " - 7s - loss: 0.3775 - acc: 0.9345 - binary_crossentropy: 0.3775 - val_loss: 0.4448 - val_acc: 0.8794 - val_binary_crossentropy: 0.4448\n",
      "Epoch 6/20\n",
      " - 7s - loss: 0.3545 - acc: 0.9464 - binary_crossentropy: 0.3545 - val_loss: 0.4459 - val_acc: 0.8728 - val_binary_crossentropy: 0.4459\n",
      "Epoch 7/20\n",
      " - 8s - loss: 0.3341 - acc: 0.9542 - binary_crossentropy: 0.3341 - val_loss: 0.4451 - val_acc: 0.8707 - val_binary_crossentropy: 0.4451\n",
      "Epoch 8/20\n",
      " - 7s - loss: 0.3164 - acc: 0.9606 - binary_crossentropy: 0.3164 - val_loss: 0.4362 - val_acc: 0.8748 - val_binary_crossentropy: 0.4362\n",
      "Epoch 9/20\n",
      " - 7s - loss: 0.3002 - acc: 0.9670 - binary_crossentropy: 0.3002 - val_loss: 0.4390 - val_acc: 0.8718 - val_binary_crossentropy: 0.4390\n",
      "Epoch 10/20\n",
      " - 7s - loss: 0.2858 - acc: 0.9708 - binary_crossentropy: 0.2858 - val_loss: 0.4441 - val_acc: 0.8697 - val_binary_crossentropy: 0.4441\n",
      "Epoch 11/20\n",
      " - 7s - loss: 0.2721 - acc: 0.9735 - binary_crossentropy: 0.2721 - val_loss: 0.4471 - val_acc: 0.8696 - val_binary_crossentropy: 0.4471\n",
      "Epoch 12/20\n",
      " - 7s - loss: 0.2597 - acc: 0.9768 - binary_crossentropy: 0.2597 - val_loss: 0.4554 - val_acc: 0.8675 - val_binary_crossentropy: 0.4554\n",
      "Epoch 13/20\n",
      " - 7s - loss: 0.2482 - acc: 0.9798 - binary_crossentropy: 0.2482 - val_loss: 0.4634 - val_acc: 0.8651 - val_binary_crossentropy: 0.4634\n",
      "Epoch 14/20\n",
      " - 7s - loss: 0.2375 - acc: 0.9814 - binary_crossentropy: 0.2375 - val_loss: 0.4532 - val_acc: 0.8672 - val_binary_crossentropy: 0.4532\n",
      "Epoch 15/20\n",
      " - 7s - loss: 0.2276 - acc: 0.9830 - binary_crossentropy: 0.2276 - val_loss: 0.4669 - val_acc: 0.8662 - val_binary_crossentropy: 0.4669\n",
      "Epoch 16/20\n",
      " - 7s - loss: 0.2183 - acc: 0.9848 - binary_crossentropy: 0.2183 - val_loss: 0.4748 - val_acc: 0.8644 - val_binary_crossentropy: 0.4748\n",
      "Epoch 17/20\n",
      " - 8s - loss: 0.2101 - acc: 0.9852 - binary_crossentropy: 0.2101 - val_loss: 0.4824 - val_acc: 0.8631 - val_binary_crossentropy: 0.4824\n",
      "Epoch 18/20\n",
      " - 7s - loss: 0.2021 - acc: 0.9858 - binary_crossentropy: 0.2021 - val_loss: 0.4652 - val_acc: 0.8651 - val_binary_crossentropy: 0.4652\n",
      "Epoch 19/20\n",
      " - 7s - loss: 0.1950 - acc: 0.9862 - binary_crossentropy: 0.1950 - val_loss: 0.4893 - val_acc: 0.8632 - val_binary_crossentropy: 0.4893\n",
      "Epoch 20/20\n",
      " - 7s - loss: 0.1878 - acc: 0.9867 - binary_crossentropy: 0.1878 - val_loss: 0.5051 - val_acc: 0.8614 - val_binary_crossentropy: 0.5051\n"
     ]
    }
   ],
   "source": [
    "smaller_history = smaller_model.fit(train_data,\n",
    "                                   train_labels,\n",
    "                                   epochs=20,\n",
    "                                   batch_size=512,\n",
    "                                   validation_data=(test_data, test_labels),\n",
    "                                   verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
